{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "collab_filter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHAyYFuPcaOFow6Mms5eIL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saikrishna2999/hello-world/blob/master/collab_filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoaQaz-o2j3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class MF():\n",
        "\n",
        "    def __init__(self, R, K, alpha, beta, iterations):\n",
        "        \"\"\"\n",
        "        Perform matrix factorization to predict empty\n",
        "        entries in a matrix.\n",
        "\n",
        "        Arguments\n",
        "        - R (ndarray)   : user-item rating matrix\n",
        "        - K (int)       : number of latent dimensions\n",
        "        - alpha (float) : learning rate\n",
        "        - beta (float)  : regularization parameter\n",
        "        \"\"\"\n",
        "\n",
        "        self.R = R\n",
        "        self.num_users, self.num_items = R.shape\n",
        "        self.K = K\n",
        "        self.alpha = alpha\n",
        "        self.beta = beta\n",
        "        self.iterations = iterations\n",
        "\n",
        "    def train(self):\n",
        "        # Initialize user and item latent feature matrice\n",
        "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K))\n",
        "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K))\n",
        "\n",
        "        # Initialize the biases\n",
        "        self.b_u = np.zeros(self.num_users)\n",
        "        self.b_i = np.zeros(self.num_items)\n",
        "        self.b = np.mean(self.R[np.where(self.R != 0)])\n",
        "\n",
        "        # Create a list of training samples\n",
        "        self.samples = [\n",
        "            (i, j, self.R[i, j])\n",
        "            for i in range(self.num_users)\n",
        "            for j in range(self.num_items)\n",
        "            if self.R[i, j] > 0\n",
        "        ]\n",
        "\n",
        "        # Perform stochastic gradient descent for number of iterations\n",
        "        training_process = []\n",
        "        for i in range(self.iterations):\n",
        "            np.random.shuffle(self.samples)\n",
        "            self.sgd()\n",
        "            mse = self.mse()\n",
        "            training_process.append((i, mse))\n",
        "            if (i+1) % 10 == 0:\n",
        "                print(\"Iteration: %d ; error = %.4f\" % (i+1, mse))\n",
        "\n",
        "        return training_process\n",
        "\n",
        "    def mse(self):\n",
        "        \"\"\"\n",
        "        A function to compute the total mean square error\n",
        "        \"\"\"\n",
        "        xs, ys = self.R.nonzero()\n",
        "        predicted = self.full_matrix()\n",
        "        error = 0\n",
        "        for x, y in zip(xs, ys):\n",
        "            error += pow(self.R[x, y] - predicted[x, y], 2)\n",
        "        return np.sqrt(error)\n",
        "\n",
        "    def sgd(self):\n",
        "        \"\"\"\n",
        "        Perform stochastic graident descent\n",
        "        \"\"\"\n",
        "        for i, j, r in self.samples:\n",
        "            # Computer prediction and error\n",
        "            prediction = self.get_rating(i, j)\n",
        "            e = (r - prediction)\n",
        "\n",
        "            # Update biases\n",
        "            self.b_u[i] += self.alpha * (e - self.beta * self.b_u[i])\n",
        "            self.b_i[j] += self.alpha * (e - self.beta * self.b_i[j])\n",
        "\n",
        "            # Update user and item latent feature matrices\n",
        "            self.P[i, :] += self.alpha * (e * self.Q[j, :] - self.beta * self.P[i,:])\n",
        "            self.Q[j, :] += self.alpha * (e * self.P[i, :] - self.beta * self.Q[j,:])\n",
        "\n",
        "    def get_rating(self, i, j):\n",
        "        \"\"\"\n",
        "        Get the predicted rating of user i and item j\n",
        "        \"\"\"\n",
        "        prediction = self.b + self.b_u[i] + self.b_i[j] + self.P[i, :].dot(self.Q[j, :].T)\n",
        "        return prediction\n",
        "\n",
        "    def full_matrix(self):\n",
        "        \"\"\"\n",
        "        Computer the full matrix using the resultant biases, P and Q\n",
        "        \"\"\"\n",
        "        return self.b + self.b_u[:,np.newaxis] + self.b_i[np.newaxis:,] + self.P.dot(self.Q.T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYvFC2m768U1",
        "colab_type": "code",
        "outputId": "38db8392-7bc2-498f-897c-40c11d232690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "R = np.array([\n",
        "    [5, 3, 0, 1],\n",
        "    [4, 0, 0, 1],\n",
        "    [1, 1, 0, 5],\n",
        "    [1, 0, 0, 4],\n",
        "    [0, 1, 5, 4],\n",
        "])\n",
        "\n",
        "mf = MF(R, K=2, alpha=0.1, beta=0.01, iterations=20)\n",
        "training_process = mf.train()\n",
        "print()\n",
        "print(\"P x Q:\")\n",
        "print(mf.full_matrix())\n",
        "print()\n",
        "print(\"Global bias:\")\n",
        "print(mf.b)\n",
        "print()\n",
        "print(\"User bias:\")\n",
        "print(mf.b_u)\n",
        "print()\n",
        "print(\"Item bias:\")\n",
        "print(mf.b_i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 10 ; error = 0.0956\n",
            "Iteration: 20 ; error = 0.0373\n",
            "\n",
            "P x Q:\n",
            "[[4.98746746 2.99832707 3.02280654 1.01456112]\n",
            " [3.99470256 1.91056337 2.80166467 1.01115284]\n",
            " [1.00587226 1.00775745 4.45583605 4.98651123]\n",
            " [1.01354387 2.62244092 3.25307353 3.99685184]\n",
            " [3.40238935 1.01552069 4.98802331 3.99656309]]\n",
            "\n",
            "Global bias:\n",
            "2.769230769230769\n",
            "\n",
            "User bias:\n",
            "[ 0.40385023 -0.27907698 -0.20777171 -0.03013047  0.26207173]\n",
            "\n",
            "Item bias:\n",
            "[ 0.17802444 -0.77039214  0.7697422  -0.0015025 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUBwEza17BCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}